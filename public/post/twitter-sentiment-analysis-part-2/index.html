<!DOCTYPE html>
<html lang="en-us"><head>
  <meta charset="utf-8">
  <title>Twitter Sentiment Analysis Part:2</title>

  <!-- mobile responsive meta -->
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Data Science Portfilio">
  
  <meta name="author" content="Themefisher">
  <meta name="generator" content="Hugo 0.111.3">

  <!-- plugins -->
  
  <link rel="stylesheet" href="https://nervous-wright-ea05a8.netlify.com/plugins/bootstrap/bootstrap.min.css ">
  
  <link rel="stylesheet" href="https://nervous-wright-ea05a8.netlify.com/plugins/themify-icons/themify-icons.css ">
  

  <!-- Main Stylesheet -->
  
  <link rel="stylesheet" href="https://nervous-wright-ea05a8.netlify.com/scss/style.min.css" media="screen">

  <!--Favicon-->
  <link rel="shortcut icon" href="https://nervous-wright-ea05a8.netlify.com/images/favicon.png " type="image/x-icon">
  <link rel="icon" href="https://nervous-wright-ea05a8.netlify.com/images/favicon.png " type="image/x-icon">

</head><body>
<!-- preloader start -->
<div class="preloader">
  
</div>
<!-- preloader end -->
<!-- navigation -->
<header class="fixed-top navigation">
  <div class="container">
    
    <nav class="navbar navbar-expand-lg navbar-light bg-transparent">
      <a class="navbar-brand"href="https://nervous-wright-ea05a8.netlify.com/"><img class="img-fluid" src="/images/resume.png" alt="Kevin Bonds | Portfolio"></a>
      <button class="navbar-toggler border-0" type="button" data-toggle="collapse" data-target="#navigation">
        <i class="ti-menu h3"></i>
      </button>

      <div class="collapse navbar-collapse text-center" id="navigation">
        <ul class="navbar-nav ml-auto">
          <li class="nav-item">
            <a class="nav-link" href="https://nervous-wright-ea05a8.netlify.com/"> Home </a>
          </li>
          
            
            <li class="nav-item">
              <a class="nav-link" href="https://nervous-wright-ea05a8.netlify.com/resume">Resumé</a>
            </li>
            
          
            
            <li class="nav-item">
              <a class="nav-link" href="https://nervous-wright-ea05a8.netlify.com/contact">Contact</a>
            </li>
            
          
            
            <li class="nav-item">
              <a class="nav-link" href="https://github.com/kwbonds?tab=repositories">Project Repos</a>
            </li>
            
          
        </ul>
        
        <!-- search -->
        <div class="search">
          <button id="searchOpen" class="search-btn"><i class="ti-search"></i></button>
          <div class="search-wrapper">
            <form action="https://nervous-wright-ea05a8.netlify.com//search" class="h-100">
              <input class="search-box px-4" id="search-query" name="s" type="search" placeholder="Type & Hit Enter...">
            </form>
            <button id="searchClose" class="search-close"><i class="ti-close text-dark"></i></button>
          </div>
        </div>
        
      </div>
    </nav>
  </div>
</header>
<!-- /navigation --> <div class="py-5 d-none d-lg-block"></div> 

<section class="section">
  <div class="container">
    <div class="row">
      <div class="col-lg-8 mx-auto block shadow mb-5">
        <h2>Twitter Sentiment Analysis Part:2</h2>
        <div class="mb-3"><span>by <a href="/author/kevin-bonds">Kevin bonds</a></span>,
          <span>at 03 January 2020</span>, category :
          
          <a href="/categories/sentiment-analysis">Sentiment analysis</a>
          
          <a href="/categories/text-analysis">Text analysis</a>
          
        </div>
        
        <div class="content mb-5">
          </p>
<div id="libraries-used" class="section level3">
<h3>Libraries Used</h3>
<pre class="r"><code>library(tidyverse)
library(readr)
library(ggplot2)
library(caret)
library(knitr)
library(quanteda)
library(doSNOW)
library(gridExtra)
library(quanteda.textplots)</code></pre>
<p>In the first part we trained a single decision tree with our document-frequency matrix using just the tokenized text. i.e. simple Bag-of-words approach. Now let’s see if I can use some n-grams to add some word order element to our approach to see if we get better results. The one caveat is that creating n-grams explodes our feature space quite significantly. Even a modest approach leads to tens-of-thousands of features and a very sparse feature matrix. Also, since I are doing this on a small laptop this quickly grows into something unwieldy. Therefore I will not go through the interim step of building a similar single decision tree model with this larger feature matrix. Instead I will use a technique to reduce this feature space down to a manageable level. I’ll use Singular Value Decomposition to achieve this.</p>
</div>
<div id="tf-idf" class="section level3">
<h3>TF-IDF</h3>
<p>So let’s create a term-frequency inverse frequency matrix to train on. This adds some weight to the words that make up the term in a document. Instead of a count of the number of times a word appears in a document we get a proportion.</p>
<pre class="r"><code>train_tfidf &lt;- dfm_tfidf(train_dfm, scheme_tf = &#39;prop&#39;)</code></pre>
<p>Check if we have any incomplete cases.</p>
<pre class="r"><code>which(!complete.cases(as.matrix(train_tfidf)))</code></pre>
<pre><code>## integer(0)</code></pre>
<p>Good we have none. Now create a dataframe and clean up any problematic token names we might have as a precaution.</p>
<pre class="r"><code>train_tfidf_df &lt;- cbind(Sentiment = train$Sentiment, data.frame(train_tfidf))
names(train_tfidf_df) &lt;- make.names(names(train_tfidf_df))</code></pre>
</div>
<div id="n-grams" class="section level3">
<h3>N-Grams</h3>
<p>We can use the below method to create any number of N-grams or combinations of works. Let’s create some bigrams and see if this will improve our score. This will make our feature space very wide and be quite computationally expensive. In order to run this on a small laptop we will need to do some dimensionality reduction before trying to run any models with these bigrams. Later we may try some skip-grams as well.</p>
<pre class="r"><code>train_tokens &lt;- tokens_ngrams(train_tokens, n = c(1,2))
train_tokens[[2]]</code></pre>
<pre><code>##  [1] &quot;think&quot;          &quot;felt&quot;           &quot;realli&quot;         &quot;sick&quot;          
##  [5] &quot;depress&quot;        &quot;school&quot;         &quot;today&quot;          &quot;cuz&quot;           
##  [9] &quot;stress&quot;         &quot;glad&quot;           &quot;got&quot;            &quot;chest&quot;         
## [13] &quot;think_felt&quot;     &quot;felt_realli&quot;    &quot;realli_sick&quot;    &quot;sick_depress&quot;  
## [17] &quot;depress_school&quot; &quot;school_today&quot;   &quot;today_cuz&quot;      &quot;cuz_stress&quot;    
## [21] &quot;stress_glad&quot;    &quot;glad_got&quot;       &quot;got_chest&quot;</code></pre>
<p>Taking a look at a few terms we have created.</p>
<pre class="r"><code>train_tokens[[4]]</code></pre>
<pre><code>## [1] &quot;hug&quot;                &quot;@ignorantsheep&quot;     &quot;hug_@ignorantsheep&quot;</code></pre>
<p>Now coverting to a matrix.</p>
<pre class="r"><code>train_matrix &lt;- as.matrix(train_dfm)
train_dfm</code></pre>
<pre><code>## Document-feature matrix of: 4,732 documents, 9,581 features (99.92% sparse) and 0 docvars.
##        features
## docs    case feel emo camp wee bit alr bring human right
##   text1    1    2   1    1   1   1   1     1     1     1
##   text2    0    0   0    0   0   0   0     0     0     0
##   text3    0    0   0    0   0   0   0     0     0     0
##   text4    0    0   0    0   0   0   0     0     0     0
##   text5    0    0   0    0   0   0   0     0     0     0
##   text6    0    0   0    0   0   0   0     0     0     0
## [ reached max_ndoc ... 4,726 more documents, reached max_nfeat ... 9,571 more features ]</code></pre>
<p>A quick peak at the wordcloud.</p>
<pre class="r"><code># Create wordcloud
train_dfm %&gt;% textplot_wordcloud()</code></pre>
<p><img src="/post/2019-12-16-twitter-sentiment-analysis-part-2_files/figure-html/wordcloud2-1.png" width="672" /></p>
<p>Converting the <code>train_dfm</code> to a matrix so that we can column-bind it to the Sentiment scores as a dataframe.</p>
<pre class="r"><code># Convert to matrix
train_dfm &lt;- as.matrix(train_dfm)</code></pre>
<pre class="r"><code># Bind the DFM, Sentiment together as a dataframe
train_df &lt;- cbind(&quot;Sentiment&quot; = as.factor(train$Sentiment), 
                  as.data.frame(train_dfm))</code></pre>
<p>Again make sure names are clean.</p>
<pre class="r"><code># Alter any names that don&#39;t work as columns
names(train_df) &lt;- make.names(names(train_df), 
                              unique = TRUE)</code></pre>
<p>Garbage collection.</p>
<pre class="r"><code>gc()</code></pre>
<pre><code>##             used   (Mb) gc trigger   (Mb) limit (Mb)  max used   (Mb)
## Ncells   2810877  150.2    4343145  232.0         NA   4343145  232.0
## Vcells 187561734 1431.0  298858176 2280.2      32768 207416933 1582.5</code></pre>
<p>Set up our Multifolds and train control for 30 partitions.</p>
<pre class="r"><code># Set seed
set.seed(42)
# Define indexes for the training control 
cv_folds &lt;- createMultiFolds(train$Sentiment, 
                             k = 10, times = 3)
# Build training control object
cv_cntrl &lt;- trainControl(method = &quot;repeatedcv&quot;, 
                         number = 10,
                         repeats = 3, 
                         index = cv_folds)</code></pre>
<pre class="r"><code># Train a decision tree model using 
# the training control we setup
#start.time &lt;- Sys.time()

# Create a cluster to work on 10 logical cores.
#cl &lt;- makeCluster(3, type = &quot;SOCK&quot;)
#registerDoSNOW(cl)

# rpart2 &lt;- train(Sentiment ~ ., 
#                 data = train_df, 
#                 method = &quot;rpart&quot;, 
#                 trControl = cv_cntrl, 
#                 tuneLength = 7)
 
 # Processing is done, stop cluster.
#stopCluster(cl)

# Total time of execution on workstation was 
#total.time &lt;- Sys.time() - start.time
#total.time</code></pre>
<p>Use the irlba package for Sigular Value Decomposition</p>
<pre class="r"><code>library(irlba)</code></pre>
<pre><code>## Loading required package: Matrix</code></pre>
<pre><code>## 
## Attaching package: &#39;Matrix&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:tidyr&#39;:
## 
##     expand, pack, unpack</code></pre>
<pre class="r"><code>train_tfidf</code></pre>
<pre><code>## Document-feature matrix of: 4,732 documents, 9,581 features (99.92% sparse) and 0 docvars.
##        features
## docs         case      feel       emo      camp       wee       bit       alr
##   text1 0.1750632 0.1821106 0.1881131 0.1526979 0.1984715 0.1301557 0.2161791
##   text2 0         0         0         0         0         0         0        
##   text3 0         0         0         0         0         0         0        
##   text4 0         0         0         0         0         0         0        
##   text5 0         0         0         0         0         0         0        
##   text6 0         0         0         0         0         0         0        
##        features
## docs        bring     human     right
##   text1 0.1437998 0.1984715 0.1015091
##   text2 0         0         0        
##   text3 0         0         0        
##   text4 0         0         0        
##   text5 0         0         0        
##   text6 0         0         0        
## [ reached max_ndoc ... 4,726 more documents, reached max_nfeat ... 9,571 more features ]</code></pre>
<p>Create our reduced feature space.</p>
<pre class="r"><code># Time the code execution
start.time &lt;- Sys.time()

# Perform SVD. Specifically, reduce dimensionality down to 300 columns
# for our latent semantic analysis (LSA).
train.irlba &lt;- irlba(t(as.matrix(train_tfidf)), nv = 300, maxit = 600)

# Total time of execution on workstation was 
total.time &lt;- Sys.time() - start.time
total.time</code></pre>
<pre><code>## Time difference of 2.755332 mins</code></pre>
<p>Create a new dataframe with the reduced feature space.</p>
<pre class="r"><code>train.svd &lt;- data.frame(Sentiment = train$Sentiment, train.irlba$v)</code></pre>
<p>Train a random forrest model and see if our results improve.</p>
<pre class="r"><code># Create a cluster
cl &lt;- makeCluster(4, type = &quot;SOCK&quot;)
 registerDoSNOW(cl)

# Time the code execution
start.time &lt;- Sys.time()

rf.cv.4 &lt;- train(Sentiment ~ ., data = train.svd, method = &quot;rf&quot;, 
                 trControl = cv_cntrl, tuneLength = 4)

# Stop cluster.
stopCluster(cl)

# Total time 
total.time &lt;- Sys.time() - start.time
total.time</code></pre>
<pre class="r"><code>load(file = &quot;../../rf1.rds&quot;)
rf.cv.1</code></pre>
<pre><code>## Random Forest 
## 
## 4732 samples
##  500 predictor
##    2 classes: &#39;Negative&#39;, &#39;Positive&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (10 fold, repeated 3 times) 
## Summary of sample sizes: 4258, 4258, 4259, 4259, 4259, 4260, ... 
## Resampling results across tuning parameters:
## 
##   mtry  Accuracy   Kappa    
##     2   0.6647551  0.3295559
##    12   0.6767312  0.3535059
##    79   0.6799018  0.3598693
##   500   0.6732108  0.3465657
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was mtry = 79.</code></pre>
<p>Outputting the model results we see that we have an accuracy of 68% accuracy. This is still not great. We can’t expect to get very high accuracy with this data. Tweets is especially ripe with scarcasm and other problems that makes sentiment analysis difficult. I was hoping for 80%-90% accuracy, but this may not be possible with decision trees. We can try some other feature engineering techniques, but it is unlikely we will improve much more without some sort of breakthrough.</p>
</div>
<div id="combine-skipgrams-with-n-grams" class="section level3">
<h3>Combine Skipgrams with N-grams</h3>
<p>The next thing we can try is using skipgrams or maybe a combination of skip-grams and n-grams. Here is an example of skip grams.</p>
<pre class="r"><code>train_tokens2 &lt;- tokens_skipgrams(train_tokens, n = 2, skip = 1)
train_tokens2[[2]]</code></pre>
<pre><code>##  [1] &quot;think_realli&quot;               &quot;felt_sick&quot;                 
##  [3] &quot;realli_depress&quot;             &quot;sick_school&quot;               
##  [5] &quot;depress_today&quot;              &quot;school_cuz&quot;                
##  [7] &quot;today_stress&quot;               &quot;cuz_glad&quot;                  
##  [9] &quot;stress_got&quot;                 &quot;glad_chest&quot;                
## [11] &quot;got_think_felt&quot;             &quot;chest_felt_realli&quot;         
## [13] &quot;think_felt_realli_sick&quot;     &quot;felt_realli_sick_depress&quot;  
## [15] &quot;realli_sick_depress_school&quot; &quot;sick_depress_school_today&quot; 
## [17] &quot;depress_school_today_cuz&quot;   &quot;school_today_cuz_stress&quot;   
## [19] &quot;today_cuz_stress_glad&quot;      &quot;cuz_stress_glad_got&quot;       
## [21] &quot;stress_glad_got_chest&quot;</code></pre>
<div id="to-be-continued" class="section level4">
<h4>To be continued…</h4>
<p>All of this started to get really heavy for my small, old macbook. So I stoped here for now.</p>
<p>Update: I started a new job, so I’ve been focused on that and haven’t worked on this.</p>
</div>
</div>

        </div>
      </div>
      <div class="col-lg-8 mx-auto block shadow">
        
        
      </div>
    </div>
  </div>
</section>


<footer class="py-4 bg-light border-top">
  <div class="container">
    <div class="row justify-content-between align-items-center">
      <div class="col-lg-4 text-center text-lg-left mb-4 mb-lg-0">
        <a href="https://nervous-wright-ea05a8.netlify.com/"><img src="/images/resume.png" class="img-fluid"
            alt="Kevin Bonds | Portfolio"></a>
      </div>
      <div class="col-lg-4 text-center mb-4 mb-lg-0">
        <ul class="list-inline mb-0">
          
          <li class="list-inline-item"><a class="text-dark d-block p-2" href="https://nervous-wright-ea05a8.netlify.com/resume">Resumé</a>
          </li>
          
          <li class="list-inline-item"><a class="text-dark d-block p-2" href="https://nervous-wright-ea05a8.netlify.com/contact">Contact</a>
          </li>
          
          <li class="list-inline-item"><a class="text-dark d-block p-2" href="https://github.com/kwbonds?tab=repositories">Project Repos</a>
          </li>
          
        </ul>
      </div>
      <div class="col-lg-4 text-lg-right text-center mb-4 mb-lg-0">
        <ul class="list-inline social-icon mb-0">
          
          <li class="list-inline-item"><a href="https://join.skype.com/invite/u45PzQhKsLp5"><i class="ti-skype"></i></a></li>
          
          <li class="list-inline-item"><a href="https://github.com/kwbonds"><i class="ti-github"></i></a></li>
          
          <li class="list-inline-item"><a href="https://www.linkedin.com/in/kevin-bonds/"><i class="ti-linkedin"></i></a></li>
          
        </ul>
      </div>
      <div class="col-12 text-center mt-4">
        <span></span>
      </div>
    </div>
  </div>
</footer>




<script>
  var indexURL = "https://nervous-wright-ea05a8.netlify.com/index.json"
</script>


<!-- JS Plugins -->

<script src="https://nervous-wright-ea05a8.netlify.com/plugins/jQuery/jquery.min.js"></script>

<script src="https://nervous-wright-ea05a8.netlify.com/plugins/bootstrap/bootstrap.min.js"></script>

<script src="https://nervous-wright-ea05a8.netlify.com/plugins/search/fuse.min.js"></script>

<script src="https://nervous-wright-ea05a8.netlify.com/plugins/search/mark.js"></script>

<script src="https://nervous-wright-ea05a8.netlify.com/plugins/search/search.js"></script>

<!-- Main Script -->

<script src="https://nervous-wright-ea05a8.netlify.com/js/script.min.js"></script>
<!-- google analitycs -->
<script>
  (function (i, s, o, g, r, a, m) {
    i['GoogleAnalyticsObject'] = r;
    i[r] = i[r] || function () {
      (i[r].q = i[r].q || []).push(arguments)
    }, i[r].l = 1 * new Date();
    a = s.createElement(o),
      m = s.getElementsByTagName(o)[0];
    a.async = 1;
    a.src = g;
    m.parentNode.insertBefore(a, m)
  })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');
  ga('create', 'UA-113458466-2', 'auto');
  ga('send', 'pageview');
</script></body>
</html>