<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AB-Testing on Kevin Bonds | Portfolio</title>
    <link>https://nervous-wright-ea05a8.netlify.app/tags/ab-testing/</link>
    <description>Recent content in AB-Testing on Kevin Bonds | Portfolio</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 07 Jun 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://nervous-wright-ea05a8.netlify.app/tags/ab-testing/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>A/B/N Testing in Python</title>
      <link>https://nervous-wright-ea05a8.netlify.app/post/abn-testing-python/</link>
      <pubDate>Sat, 07 Jun 2025 00:00:00 +0000</pubDate>
      <guid>https://nervous-wright-ea05a8.netlify.app/post/abn-testing-python/</guid>
      <description>&lt;p&gt;The following case study will illustrate how to analyze the results for an A/N Test (or multitest). An A/N Test is a type of A/B Test in which multiple variants are tested at the same time.&lt;/p&gt;&#xA;&lt;p&gt;We’ll compare 2 variants, against a control, to increase purchase rate on a fictional website. Since testing multiple variants at once increases the error rate (known as Family Wise Error Rate–FWER), we’ll use a correction when determining statistical significance.&lt;/p&gt;&#xA;&lt;p&gt;Along the way, I’ll warn against some common mistakes when designing and interpreting results of experiments. And touch on the sticky subject of &lt;em&gt;P-values&lt;/em&gt; and what they mean (and don’t mean). Hope you find it informative.</description>
    </item>
  </channel>
</rss>
